% Chapter 6: Conclusion and Future Work
% TODO: Remove DRAFTING comments before final submission

\section{Summary of Contributions}

This thesis investigated detector consensus and descriptor fusion for local feature matching, with the following contributions:

\begin{enumerate}
    \item \textbf{Detector Intersection as Quality Filter}: Keypoints detected by multiple distinct detectors are more distinctive than those found by any single detector. This effect holds for both SIFT-SURF and SIFT-KeyNet intersections, with HardNet achieving 82.4\% mAP on intersection keypoints---a 25\% relative improvement.

    \item \textbf{Color HPatches Benchmark}: We created a color version of the HPatches patch benchmark by re-extracting 65$\times$65 color patches from original images. This enables evaluation of color descriptors like HoNC.

    \item \textbf{Magnitude Matching for Cross-Family Fusion}: Cross-family fusion (SIFT+CNN) requires pre-fusion L2 normalization to ensure equal contribution from each descriptor. With proper normalization, SIFT+HardNet achieves 46.0\% mAP on patches.

    \item \textbf{Complementary Descriptor Fusion}: Pairing a ``discriminator'' (HoNC, high verification-to-matching ratio) with a ``matcher'' (CNN) yields substantial improvements. HoNC+SOSNet concatenation achieves 50.6\% mAP on the color patch benchmark, outperforming all individual descriptors.

    \item \textbf{Scale Control Methodology}: Filtering keypoints by scale yields large improvements: +39\% relative for SIFT-family descriptors and +21\% relative for CNN descriptors.

    \item \textbf{DescriptorWorkbench Framework}: We developed an open-source evaluation framework implementing image matching, keypoint verification, and keypoint retrieval metrics from Bojanic et al.~\cite{bojanic2020comparison}, supporting both full-image and patch-based evaluation.
\end{enumerate}

\section{Key Findings}

Our experiments reveal several insights for local feature matching:

\begin{itemize}
    \item \textbf{Quality over quantity}: Fewer, better keypoints (scale-filtered or intersection-filtered) outperform larger sets of lower-quality keypoints.

    \item \textbf{Detector agreement provides quality signal}: Keypoints detected by multiple distinct methods are more reliable, with 17--25\% improvements from intersection filtering.

    \item \textbf{Magnitude matching enables cross-family fusion}: Pre-fusion L2 normalization allows successful SIFT+CNN combination by ensuring equal contribution from each descriptor.

    \item \textbf{Complementary descriptors outperform similar ones}: HoNC+CNN fusion outperforms CNN+CNN or SIFT+SIFT because the descriptors capture different information (color vs. learned features).

    \item \textbf{Concatenation preserves information}: Concatenation consistently outperforms averaging by preserving complementary features.
\end{itemize}

\section{Practical Recommendations}

Based on our findings, we offer the following recommendations:

\begin{enumerate}
    \item \textbf{For best patch matching}: Use HoNC+SOSNet concatenation (50.6\% mAP), leveraging color discrimination with learned matching.

    \item \textbf{For best full-image matching}: Use HardNet on detector intersection keypoints (82.4\% mAP), or HardNet+SOSNet concatenation (93.4\% mAP) for highest accuracy.

    \item \textbf{For cross-family fusion}: Always L2 normalize each descriptor component before fusion to ensure equal contribution.

    \item \textbf{For traditional descriptors}: Apply scale filtering (top 25\%) and use intersection keypoints (64--75\% mAP vs 42\% baseline).
\end{enumerate}

\section{Future Work}

Several directions remain for future investigation:

\subsection{Learned Fusion Weights}

Rather than fixed $\alpha = 0.5$ weighting, learn optimal weights:
\begin{equation}
    d_{\text{fused}} = \sum_i w_i \cdot d_i, \quad \text{s.t.} \sum_i w_i = 1
\end{equation}
Weights could be learned per-dimension or globally, potentially improving cross-family fusion further.

\subsection{Additional Datasets}

Validate findings on:
\begin{itemize}
    \item Oxford5k and Paris6k (image retrieval)
    \item MegaDepth (wide-baseline matching)
    \item ETH3D (multi-view stereo)
\end{itemize}

\subsection{End-to-End Learning}

Train a joint detector-descriptor-fusion network that:
\begin{itemize}
    \item Detects keypoints with scale optimization
    \item Extracts multiple descriptor types
    \item Learns optimal fusion strategy
\end{itemize}

\subsection{Tolerance Sensitivity}

% Note: Results from overnight experiments will inform this
Systematically study the relationship between intersection tolerance and matching performance. Our hypothesis is an inverted U-curve: too strict yields few keypoints, too loose yields misaligned pairs.

\section{Closing Remarks}
% DRAFTING: Updated to reflect detector consensus and color fusion findings

This thesis demonstrates two complementary approaches to improving local feature matching. First, using multiple detectors as a consensus filter identifies high-quality keypoints that are more distinctive and repeatable than those found by any single detector. Second, fusing complementary descriptors---particularly color descriptors like HoNC with learned descriptors like SOSNet---captures information that neither descriptor provides alone.

A key technical finding is that cross-family fusion (SIFT+CNN) requires proper magnitude matching through pre-fusion L2 normalization. The initial fusion failures were not due to fundamental incompatibility between descriptor families, but rather a fixable magnitude mismatch problem.

More broadly, our findings suggest that keypoint quality deserves more attention. The 39\% improvement from scale control and 25\% improvement from detector consensus exceed many algorithmic advances, yet these filtering strategies are rarely discussed in the literature. We hope this work encourages more research into keypoint selection strategies alongside descriptor algorithm development.

The DescriptorWorkbench framework, color HPatches benchmark, and all experimental configurations are available as open-source software, enabling reproduction and extension of these results.
