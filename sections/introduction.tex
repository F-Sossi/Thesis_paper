% Chapter 1: Introduction
% TODO: Remove DRAFTING comments before final submission

Local feature or keypoint detection and description remain fundamental to many computer vision applications, including simultaneous localization and mapping (SLAM), structure from motion (SfM), image retrieval, and visual place recognition. Despite advances in end to end learned approaches, local feature methods remain competitive due to their interpretability, efficiency, and ability to handle wide baseline matching.

\section{Motivation}

The computer vision community has developed several approaches to local feature extraction, which comprises two stages. \textit{Detection} identifies salient image locations corners, blobs, or edge junctions that are likely to be found again under changes in viewpoint, scale, or illumination. \textit{Description} encodes the local image appearance around each detected keypoint as a fixed-length vector, enabling efficient comparison across images. The quality of both stages determines overall matching performance, though they are often studied and optimized independently:

\begin{itemize}
    \item \textbf{Traditional methods} such as SIFT~\cite{lowe2004distinctive} and SURF~\cite{bay2006surf} use hand crafted detectors based on scale space analysis and descriptors based on gradient histograms. These methods are well understood and deterministic.

    \item \textbf{Learned methods} such as KeyNet~\cite{barroso2019key} for detection and HardNet~\cite{mishchuk2017working} and SOSNet~\cite{tian2019sosnet} for description use convolutional neural networks trained on correspondence tasks. These achieve higher matching accuracy but are trained for specific detector descriptor pairings.

    \item \textbf{Color descriptors} such as HoNC (Histogram of Normalized Colors)~\cite{olson2016keypoint} capture chromatic information that gradient based methods discard. These descriptors excel at discrimination (high verification accuracy) but show a larger performance gap between viewpoint and illumination sequences than learned descriptors in our experiments (Section~\ref{sec:patch_results}), consistent with the dependence of color histograms on photometric stability.
\end{itemize}

Each approach has distinct strengths. This raises a practical question: can we put these complementary capabilities together without compromising robustness?

During development, we observed that \textit{detector agreement provides a quality signal}. When two distinct detection methods whether SIFT and SURF (both gradient based but with different scale space representations) or SIFT and KeyNet (traditional and learned) both identify a keypoint at the same image location, this agreement indicated a distinctive feature. Different detectors select points based on different criteria; when they agree, the underlying image structure is distinctive across multiple representations. We hypothesize that such consensus keypoints are more repeatable and discriminative than those found by any single detector alone.

Our second set of experiments determined that \textit{complementary descriptors can be fused} when their characteristics are compatible. Color descriptors like HoNC provide strong discriminative power (rejecting false matches), while learned descriptors like HardNet and SOSNet provide robust matching under geometric and photometric changes. Combining a ``discriminator'' with a ``matcher'' can outperform either alone. However, not all fusion strategies succeed. For example, fusing SIFT with CNN descriptors requires careful normalization to ensure equal contribution; without it, the fusion can underperform the individual descriptors.

\section{Research Questions}

This thesis investigates the following research questions:

\begin{enumerate}
    \item \textbf{RQ1: Detector Consensus.} Does spatial agreement between different keypoint detectors (SIFT and KeyNet) provide a quality signal? Are consensus keypoints more distinctive and repeatable?

    \item \textbf{RQ2: Color Descriptor Fusion.} Can color descriptors (HoNC) be successfully fused with learned descriptors (HardNet, SOSNet)? What complementary information does color provide?

    \item \textbf{RQ3: Fusion Compatibility.} What determines whether descriptor fusion succeeds or fails? Are there systematic patterns based on descriptor characteristics?

    \item \textbf{RQ4: Scale Impact.} How does keypoint scale distribution affect descriptor matching performance? Is keypoint quality more important than descriptor algorithm choice?
\end{enumerate}

\section{Contributions}

This thesis makes the following contributions:

\begin{enumerate}
    \item \textbf{Detector Intersection as Quality Filter.} Keypoints detected by multiple detectors are more distinctive than those found by a single detector. HardNet computed at SIFT KeyNet intersection keypoints achieves 82.4\% mAP a 25\% relative improvement over the full keypoint set and the best single descriptor result in our study. This supports the claim that detector consensus identifies high quality features.

    \item \textbf{Color HPatches Benchmark.} We create a color version of the HPatches patch benchmark by re-extracting 65$\times$65 color patches from the original images using stored keypoint locations and homographies. This enables evaluation of color aware descriptors that cannot be tested on the original gray scale patches.

    \item \textbf{Complementary Descriptor Fusion.} Fusing color descriptors with learned descriptors yields substantial improvements. HoNC+SOSNet concatenation achieves 50.6\% mAP on the color patch benchmark, outperforming all individual descriptors. HoNC acts as a ``discriminator'' (high verification to matching ratio of 3.84$\times$) that complements CNN ``matchers'' (ratio of 1.84$\times$).

    \item \textbf{Magnitude Matching for Cross Family Fusion.} Cross family fusion (SIFT+CNN) requires pre fusion L2 normalization to ensure equal contribution from each descriptor. With proper normalization, SIFT+HardNet achieves 46.0\% mAP on patches.

    \item \textbf{Scale Control Methodology.} Filtering keypoints by scale improves matching performance: +39\% relative for SIFT family descriptors and +21\% relative for CNN descriptors. Keypoint quality is as important as descriptor algorithm choice.

    \item \textbf{DescriptorWorkbench Framework.} We develop an open source evaluation framework implementing the image matching, keypoint verification, and keypoint retrieval metrics from Bojanic et al.~\cite{bojanic2020comparison}, supporting both full image and patch based evaluation.
\end{enumerate}

\section{Thesis Organization}

The remainder of this thesis is organized as follows:

\begin{itemize}
    \item \textbf{Chapter~\ref{chap:background}} reviews local feature detection and description literature.

    \item \textbf{Chapter~\ref{chap:methodology}} describes our detector intersection methodology, color patch dataset construction, and evaluation framework.

    \item \textbf{Chapter~\ref{chap:results}} presents experimental results from over 100 experiments on the HPatches benchmark, analyzing detector consensus effects, color descriptor fusion, and scale control.

    \item \textbf{Chapter~\ref{chap:discussion}} interprets the results, explaining why detector consensus provides quality signal and why certain descriptor fusion strategies succeed.

    \item \textbf{Chapter~\ref{chap:conclusion}} summarizes findings and discusses future work directions.
\end{itemize}
